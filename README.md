# InterpretabilityBlog

This project attempts to interprete the decision-making mechanisms for transformer-based ML models completing question and answering tasks. I selected this particular type of task because I believe that is one of the core functions and use cases of many large language models (LLMs) such as ChatGPT. 

I envisioned myself as a student using a tool like ChatGPT to help me answer questions based on given background context or an article. I wanted to analyze why a given LLM makes its decision from context and input. One of the main topics I intended to explore was token importance, or understanding which tokens were most important in generating the machine's final answer. I wanted to synthesize all of my findings, discussion, and next steps beyond this README file by implementing an interactive blog post.

Below, I wanted to outline some of the specifics of my data, methodology, and how to implement your own demo.

https://interpretabilityblog.netlify.app
